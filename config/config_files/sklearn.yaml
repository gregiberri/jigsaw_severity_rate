id: "sklearn"
env:
  result_dir: 'results'
  random_seed: 0
  solver: 'sklearn-solver'
data:
  name: "jigsaw_dataset"
  params:
    dataset_path: '/home/albert/data/jigsaw'
    test_filename: 'comments_to_score.csv'
    batch_size: 1

    category_weights:
      'obscene': 0.16
      'toxic': 0.32
      'threat': 1.5
      'insult': 0.64
      'severe_toxic': 1.5
      'identity_hate': 1.5

    gpu_to_use: 0
    workers: 8
    load_into_memory: false

    clean_text: False

    tokenizer:
      name: "WordPiece"
      pretrained: False
      params:
        unk_token: "[UNK]"
      tokenize_params:
        truncation: False
        add_special_tokens: False
        max_length: null
        padding: False

      normalizer:
        name: "BertNormalizer"
        params:
          lowercase: True

      pre_tokenizer:
        name: "BertPreTokenizer"
        params: {}

      trainer:
        name: "WordPieceTrainer"
        params:
          vocab_size: 15000
          special_tokens: ["[UNK]", "[PAD]", "[CLS]", "[SEP]", "[MASK]"]

    vectorizer:
      name: 'TfidfVectorizer'

#model:
#  name: "Ridge"
#  pretrained: False
#  params:
#    alpha: 0.8

model:
  name: "XGBRegressor"
  pretrained: False
  params:
    params:
      max_depth: 6
      n_estimators: 100