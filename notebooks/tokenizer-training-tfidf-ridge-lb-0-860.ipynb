{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>How to train a Huggingface Tokenizer + TFIDF + RIDGE</center></h1>     \n",
    "\n",
    "<center><img src = \"https://i.imgur.com/iRX7hwu.png\" width = \"1000\" height = \"400\"/></center>           \n",
    "\n",
    "This notebook was inspided on the following other two notebooks:\n",
    "* https://www.kaggle.com/vitaleey/tfidf-ridge\n",
    "* https://www.kaggle.com/pablorosa01/naive-bayes-modeling-base-line\n",
    "\n",
    "<h3 style='background:orange; color:black'><center>Consider upvoting this notebook if you found it helpful.</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/albert/data/jigsaw/train.csv\"\n",
    "VALID_DATA_PATH = \"/home/albert/data/jigsaw/validation_data.csv\"\n",
    "TEST_DATA_PATH = \"/home/albert/data/jigsaw/comments_to_score.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "df_valid = pd.read_csv(VALID_DATA_PATH)\n",
    "df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.436667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.436667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137462</th>\n",
       "      <td>df957e1303ef8c68</td>\n",
       "      <td>\"\\n\\nRead more\\nYou can read more by going to ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82635</th>\n",
       "      <td>dd0b9714b24c3c66</td>\n",
       "      <td>Sounds like a deal. Thanks for hearing me out.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149206</th>\n",
       "      <td>58e756534c67c8e7</td>\n",
       "      <td>Bone to pick \\n\\nWhat makes you the rulemaker ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87807</th>\n",
       "      <td>eade5e302541c3a9</td>\n",
       "      <td>\"\\n\\n Semi-vegetarianism section \\n\\nI like Fl...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150843</th>\n",
       "      <td>72f8dfe354056f62</td>\n",
       "      <td>that seems appropriate to me. major changes ne...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32450 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "6       0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12      0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16      0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42      001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43      00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "...                  ...                                                ...   \n",
       "137462  df957e1303ef8c68  \"\\n\\nRead more\\nYou can read more by going to ...   \n",
       "82635   dd0b9714b24c3c66     Sounds like a deal. Thanks for hearing me out.   \n",
       "149206  58e756534c67c8e7  Bone to pick \\n\\nWhat makes you the rulemaker ...   \n",
       "87807   eade5e302541c3a9  \"\\n\\n Semi-vegetarianism section \\n\\nI like Fl...   \n",
       "150843  72f8dfe354056f62  that seems appropriate to me. major changes ne...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate     score  \\\n",
       "6        0.32           1.5     0.16     0.0    0.64            0.0  0.436667   \n",
       "12       0.32           0.0     0.00     0.0    0.00            0.0  0.053333   \n",
       "16       0.32           0.0     0.00     0.0    0.00            0.0  0.053333   \n",
       "42       0.32           0.0     0.16     0.0    0.64            1.5  0.436667   \n",
       "43       0.32           0.0     0.16     0.0    0.64            0.0  0.186667   \n",
       "...       ...           ...      ...     ...     ...            ...       ...   \n",
       "137462   0.00           0.0     0.00     0.0    0.00            0.0  0.000000   \n",
       "82635    0.00           0.0     0.00     0.0    0.00            0.0  0.000000   \n",
       "149206   0.00           0.0     0.00     0.0    0.00            0.0  0.000000   \n",
       "87807    0.00           0.0     0.00     0.0    0.00            0.0  0.000000   \n",
       "150843   0.00           0.0     0.00     0.0    0.00            0.0  0.000000   \n",
       "\n",
       "               y  \n",
       "6       0.436667  \n",
       "12      0.053333  \n",
       "16      0.053333  \n",
       "42      0.436667  \n",
       "43      0.186667  \n",
       "...          ...  \n",
       "137462  0.000000  \n",
       "82635   0.000000  \n",
       "149206  0.000000  \n",
       "87807   0.000000  \n",
       "150843  0.000000  \n",
       "\n",
       "[32450 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n",
    "            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n",
    "\n",
    "for category in cat_mtpl:\n",
    "    df_train[category] = df_train[category] * cat_mtpl[category]\n",
    "\n",
    "df_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n",
    "\n",
    "df_train['y'] = df_train['score']\n",
    "\n",
    "min_len = (df_train['y'] > 0).sum()  # len of toxic comments\n",
    "df_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\n",
    "df_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\n",
    "df_train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "raw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "raw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df_train_new[['comment_text']])\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train_new['y']\n",
    "comments = df_train_new['comment_text']\n",
    "tokenized_comments = tokenizer(comments.to_list())['input_ids']\n",
    "tokenized_comments\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = dummy_fun,\n",
    "    preprocessor = dummy_fun,\n",
    "    token_pattern = None)\n",
    "\n",
    "comments_tr = vectorizer.fit_transform(tokenized_comments)\n",
    "comments_tr.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.8, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Ridge(random_state=42, alpha=0.8)\n",
    "regressor.fit(comments_tr, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6684934236747708"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess val data\n",
    "less_toxic_comments = df_valid['less_toxic']\n",
    "more_toxic_comments = df_valid['more_toxic']\n",
    "\n",
    "less_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\n",
    "more_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n",
    "\n",
    "less_toxic = vectorizer.transform(less_toxic_comments)\n",
    "more_toxic = vectorizer.transform(more_toxic_comments)\n",
    "\n",
    "# make predictions\n",
    "y_pred_less = regressor.predict(less_toxic)\n",
    "y_pred_more = regressor.predict(more_toxic)\n",
    "\n",
    "(y_pred_less < y_pred_more).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenizer (deberta-v3): 0.6699880430450379\n",
    "* Tokenizer (trained): 0.6674970107612594\n",
    "* Tokenizer (trained + dirty): 0.6716819449980072\n",
    "\n",
    "** Be careful, this results suggest that the 0.86 LB score is not reliable!!! Use at your own risk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions and load submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_test['text']\n",
    "texts = tokenizer(texts.to_list())['input_ids']\n",
    "texts = vectorizer.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['prediction'] = regressor.predict(texts)\n",
    "df_test = df_test[['comment_id','prediction']]\n",
    "\n",
    "df_test['score'] = df_test['prediction']\n",
    "df_test = df_test[['comment_id','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>0.004819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>0.060385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>-0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>-0.026002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>0.056793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>0.058318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>0.043685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>0.034313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>0.042582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id     score\n",
       "0         114890  0.004819\n",
       "1         732895  0.060385\n",
       "2        1139051 -0.010972\n",
       "3        1434512 -0.026002\n",
       "4        2084821  0.056793\n",
       "...          ...       ...\n",
       "7532   504235362  0.058318\n",
       "7533   504235566  0.043685\n",
       "7534   504308177  0.004444\n",
       "7535   504570375  0.034313\n",
       "7536   504598250  0.042582\n",
       "\n",
       "[7537 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.to_csv('./submission.csv', index=False)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
